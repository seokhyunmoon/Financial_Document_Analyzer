paths:
  finanacebench: data/finanacebench
  logs_dir: data/logs
  raw_dir: data/pdfs
  elements_dir: data/processed/elements
  chunks_dir: data/processed/chunks
  embed_dir: data/processed/embeddings

# src/ingestion/elements.py
partitioning:
  strategy: hi_res
  hi_res_model_name: yolox
  languages:
    - eng
  infer_table_structure: true

cleaning:
  apply_unicode_quotes: true
  apply_clean: true
  clean_options:
    bullets: false
    extra_whitespace: true
    dashes: false

# src/ingestion/chunking.py
chunking:
  max_tokens: 256

# src/ingestion/embeddings.py
embedding:
  model_name: Qwen/Qwen3-Embedding-4B
  batch_size: 8
  normalize_embeddings: true

# src/ingestion/vectorstore.py
vectordb:
  use_docker: false
  init:
    host: localhost
    port: 8090
    grpc_port: 50061
    skip_init_checks: true
  embedded:
    persistence_data_path: "data/weaviate"
    binary_path: "/home/moon/.cache/weaviate-embedded"
    env:
      LOG_LEVEL: error
  upload:
    batch_size: 100
    concurrent_requests: 4
    upsert: true

# /src/graph/nodes/retrieve.py
qa:
  topk: 10
  retriever_mode: vector #vector, keyword, hybrid
  hybrid_alpha: 0.5
  rerank:
    enabled: false
    topk: 10

# /src/graph/nodes/generate.py
generate:
  provider: ollama
  model_name: qwen3:8b
  think: true

# /src/services/evaluate.py
evaluate:
  provider: ollama
  model_name: gpt-oss:20b
  think: high
