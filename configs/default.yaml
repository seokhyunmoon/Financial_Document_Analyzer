paths:
  finanacebench: data/finanacebench
  logs_dir: data/logs
  raw_dir: data/pdfs
  elements_dir: data/processed/elements
  chunks_dir: data/processed/chunks
  embed_dir: data/processed/embeddings
  metadata_dir: data/processed/metadata

# src/ingestion/elements.py
partitioning:
  strategy: hi_res
  hi_res_model_name: yolox
  languages:
    - eng
  infer_table_structure: true

cleaning:
  apply_unicode_quotes: true
  apply_clean: true
  clean_options:
    bullets: true
    extra_whitespace: true
    dashes: true

# src/ingestion/chunking.py
chunking:
  mode: tokens # tokens | chars
  max_tokens: 128
  max_char: 2048

# /src/ingestion/metadata.py
metadata:
  enabled: true
  provider: ollama
  model_name: qwen3:8b
  max_keywords: 6
  summary_lines: 3
  max_workers: 4
  retry: 3

# src/ingestion/embeddings.py
embedding:
  model_name: Qwen/Qwen3-Embedding-8B
  batch_size: 8
  normalize_embeddings: true

# src/ingestion/vectorstore.py
vectordb:
  use_docker: false
  init:
    host: localhost
    port: 8090
    grpc_port: 50061
    skip_init_checks: true
  embedded:
    persistence_data_path: "data/weaviate"
    binary_path: "/home/moon/.cache/weaviate-embedded"
    env:
      LOG_LEVEL: error
  upload:
    batch_size: 128
    concurrent_requests: 4
    upsert: true

# /src/graph/nodes/generate.py
generate:
  provider: ollama
  model_name: qwen3:8b
  # think: true

# Shared Ollama settings (optional global host list)
ollama:
  hosts:
    - http://127.0.0.1:11435
    # - http://127.0.0.1:11436
    # - http://127.0.0.1:11437
    # - http://127.0.0.1:11438

# /src/graph/nodes/retrieve.py
retrieve:
  topk: 10
  retriever_mode: fusion # vector | keyword | hybrid | fusion (vector+bm25 merged)
  hybrid_alpha: 0.9
  keyword_properties:
    - text
    - section_title
    - keywords
  fusion:
    vector_topk: 20
    keyword_topk: 20
    merge_topk: 10
    rrf_k: 60.0

# /src/graph/nodes/rerank.py
rerank:
  enabled: true
  model_name: qwen3:8b
  topk: 10
  max_candidates: 10
  max_tokens: 128
  # think: true

# /src/services/evaluate.py
evaluate:
  provider: ollama
  model_name: gpt-oss:20b
  # think: high
